# QuantAI - AI-Human Collaborative Quant Research Platform

An intelligent quantitative trading research platform that combines AI-powered knowledge retrieval with production-grade backtesting infrastructure.

## ğŸ¯ Overview

QuantAI is not just another trading bot - it's a **research partnership platform** designed to enhance human quant research with AI capabilities. The system features:

- **Knowledge Engine**: RAG-powered system that learns from quant books and trading experiences
- **AI Tool Framework**: Extensible function-calling framework for trading operations
- **Production-Ready Architecture**: SOLID principles, async/await, comprehensive abstractions
- **Multi-Stage Retrieval**: Advanced semantic search with re-ranking and deduplication
- **Backtesting Infrastructure**: High-performance testing framework (coming in Phase 2B)

## ğŸ—ï¸ Architecture

### Core Components

```
QuantAI/
â”œâ”€â”€ knowledge_engine/       # RAG knowledge system
â”‚   â”œâ”€â”€ ingest/            # Document processing & extraction
â”‚   â”œâ”€â”€ graph/             # Neo4j knowledge graph
â”‚   â”œâ”€â”€ retrieval/         # Multi-stage semantic search
â”‚   â””â”€â”€ experiences/       # Market insights storage
â”œâ”€â”€ backtesting/           # Backtesting infrastructure
â”‚   â”œâ”€â”€ engine/            # Core backtesting logic
â”‚   â”œâ”€â”€ data/              # Market data management
â”‚   â”œâ”€â”€ strategies/        # Strategy implementations
â”‚   â””â”€â”€ parallel/          # Multi-strategy runner
â”œâ”€â”€ ai_agent/              # AI reasoning & tools
â”‚   â”œâ”€â”€ reasoner/          # LLM & embedding providers
â”‚   â”œâ”€â”€ strategy_generator/# AI strategy creation
â”‚   â”œâ”€â”€ feedback_loop/     # Test-learn-iterate cycle
â”‚   â””â”€â”€ tools/             # AI function calling tools
â”œâ”€â”€ shared/                # Shared utilities
â”‚   â”œâ”€â”€ models/            # Pydantic models & interfaces
â”‚   â”œâ”€â”€ config/            # Configuration management
â”‚   â””â”€â”€ utils/             # URL fetcher, caching, etc.
â””â”€â”€ api/                   # FastAPI REST API
```

## âœ¨ Features

### Phase 2A - Completed âœ…

- âœ… **SOLID Architecture**: Abstract base classes for all major components
- âœ… **Async/Await**: Full async support throughout
- âœ… **URL Fetching**: Document downloading with retry logic
- âœ… **AI Tool Framework**: OpenAI & Anthropic function calling support
- âœ… **Trading Tools**: Market data, indicators, signals, metrics
- âœ… **LLM Providers**: OpenAI (GPT-4) & Anthropic (Claude) integration
- âœ… **Embedding Providers**: OpenAI, SentenceTransformers, Hybrid
- âœ… **Vector Store**: ChromaDB & FAISS implementations
- âœ… **Knowledge Graph**: Neo4j with relationship traversal
- âœ… **Document Processing**: PDF extraction with structure preservation
- âœ… **Caching Layer**: Redis with in-memory fallback
- âœ… **RAG Pipeline**: Multi-stage retrieval with re-ranking
- âœ… **REST API**: FastAPI with tool execution endpoints
- âœ… **CLI Tool**: Interactive command-line interface

### Phase 2B - In Progress ğŸš§

- âœ… **Event System**: Production event-driven architecture (10k+ events/sec)
  - Type-safe events (Market Data, Orders, Positions, Portfolio)
  - Pub/sub event bus (in-memory + Redis for multi-process)
  - Event filters with composition
  - Event persistence for replay (coming)

- ğŸš§ **Exchange Connectors**: Multi-exchange framework (in progress)
- ğŸ”œ **Order Management System**: Professional OMS with pre-trade checks
- ğŸ”œ **Portfolio Manager**: Real-time P&L and risk limits
- ğŸ”œ **Strategy Framework**: Simple event-driven strategies
- ğŸ”œ **Simulation Engine**: Data recording and replay

### Coming Later (Phase 3+)

- ğŸ”œ Full backtesting engine with vectorbt
- ğŸ”œ Parallel strategy testing
- ğŸ”œ AI strategy generator
- ğŸ”œ Feedback loop system
- ğŸ”œ Market regime detection
- ğŸ”œ Web dashboard

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Poetry (for dependency management)
- Optional: Docker (for databases)

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd QuantAI
```

2. Install dependencies:
```bash
poetry install
```

3. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your API keys and configuration
```

4. (Optional) Start databases with Docker:
```bash
# Redis
docker run -d -p 6379:6379 redis:latest

# Neo4j
docker run -d -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/password \
  neo4j:latest

# PostgreSQL
docker run -d -p 5432:5432 \
  -e POSTGRES_DB=quantai \
  -e POSTGRES_USER=quantai \
  -e POSTGRES_PASSWORD=quantai \
  postgres:latest
```

### Quick Test

Test the AI tool framework:

```bash
poetry run python cli.py list-tools
```

Test market data fetching:

```bash
poetry run python cli.py test-market-data AAPL 2023-01-01 --end-date 2024-01-01
```

Test a trading strategy:

```bash
poetry run python cli.py test-strategy AAPL --strategy MA_CROSSOVER
```

### Start the API Server

```bash
poetry run python cli.py start-api
```

Then visit http://localhost:8000/docs for the interactive API documentation.

## ğŸ“– Usage Examples

### 1. Using the CLI

**List available AI tools:**
```bash
poetry run python cli.py list-tools
```

**Interactive chat with AI:**
```bash
poetry run python cli.py chat --interactive
```

**Test a strategy:**
```bash
poetry run python cli.py test-strategy AAPL \
  --strategy MA_CROSSOVER \
  --start-date 2023-01-01 \
  --end-date 2024-01-01
```

### 2. Using the Python API

```python
import asyncio
from ai_agent.tools.trading_tools import GetMarketDataTool, GenerateSignalsTool

async def main():
    # Fetch market data
    data_tool = GetMarketDataTool()
    result = await data_tool.execute(
        symbol="AAPL",
        start_date="2023-01-01",
        end_date="2024-01-01"
    )

    if result.success:
        prices = result.result.data["close"]

        # Generate signals
        signal_tool = GenerateSignalsTool()
        signals = await signal_tool.execute(
            strategy="MA_CROSSOVER",
            prices=prices
        )

        print(f"Buy signals: {signals.result['num_buy']}")
        print(f"Sell signals: {signals.result['num_sell']}")

asyncio.run(main())
```

### 3. Using the REST API

```bash
# Execute a tool via API
curl -X POST "http://localhost:8000/tools/execute" \
  -H "Content-Type: application/json" \
  -d '{
    "tool_name": "get_market_data",
    "parameters": {
      "symbol": "AAPL",
      "start_date": "2023-01-01"
    }
  }'

# Chat with AI
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Get market data for AAPL",
    "use_tools": true
  }'
```

## ğŸ§ª Testing

Run tests:
```bash
poetry run pytest
```

With coverage:
```bash
poetry run pytest --cov=. --cov-report=html
```

## ğŸ› ï¸ Development

### Adding New AI Tools

1. Create a new tool class inheriting from `BaseTool`:

```python
from ai_agent.tools.base import BaseTool, ToolParameter, ToolParameterType, ToolResult

class MyCustomTool(BaseTool):
    @property
    def name(self) -> str:
        return "my_custom_tool"

    @property
    def description(self) -> str:
        return "Description of what this tool does"

    def get_parameters(self) -> list[ToolParameter]:
        return [
            ToolParameter(
                name="param1",
                type=ToolParameterType.STRING,
                description="Parameter description",
                required=True
            )
        ]

    async def execute(self, **kwargs) -> ToolResult:
        # Tool implementation
        result = do_something(kwargs["param1"])
        return ToolResult(success=True, result=result)
```

2. Register the tool:

```python
from ai_agent.tools.base import global_registry

global_registry.register(MyCustomTool())
```

### Project Structure

- **SOLID Principles**: All major components have abstract base interfaces in `shared/models/base.py`
- **Async First**: All I/O operations use async/await
- **Type Safety**: Pydantic models for data validation
- **Logging**: Loguru for structured logging
- **Configuration**: Pydantic Settings for environment-based config

## ğŸ“š Documentation

For detailed documentation, see:
- [Master Plan](docs/plans/broad_plan.md) - Complete implementation roadmap
- [API Documentation](http://localhost:8000/docs) - Interactive API docs (when server running)

## ğŸ”‘ Environment Variables

Key environment variables (see `.env.example` for full list):

```bash
# LLM API Keys
LLM_OPENAI_API_KEY=your-openai-key
LLM_ANTHROPIC_API_KEY=your-anthropic-key

# Database connections
DB_POSTGRES_HOST=localhost
NEO4J_URI=bolt://localhost:7687
REDIS_HOST=localhost
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Follow the existing code structure
2. Add tests for new features
3. Update documentation
4. Use type hints throughout
5. Follow async/await patterns

## ğŸ“ License

[Your License Here]

## ğŸ™ Acknowledgments

Built with:
- FastAPI - Modern web framework
- OpenAI & Anthropic - LLM providers
- ChromaDB - Vector database
- Neo4j - Graph database
- Pydantic - Data validation
- And many more excellent open-source projects

---

**Status**: Phase 2A Complete âœ…

Next up: Phase 2B - Full backtesting engine and parallel strategy testing
